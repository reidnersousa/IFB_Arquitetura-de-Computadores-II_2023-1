{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reidnersousa/IFB_Arquitetura-de-Computadores-II_2023-1/blob/main/C%C3%B3pia_de_Introducao_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Introdução a Linguagem de Programação CUDA**\n",
        "Professor João Victor de A. Oliveira\n",
        "Instituto Federal de Brasília\n",
        "\n",
        "Antes de tudo, vamos ativar nossa GPU. No menu superior, vá em *Runtime --> Change runtime type* e selecione o acelerador de hardware \"GPU\".\n",
        "\n",
        "Iremos começar com o algoritmo máis básico de todos: um **Hello World**\n"
      ],
      "metadata": {
        "id": "0kceSEvfPm1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helloWorld.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "\n",
        "int main (){\n",
        "  printf(\"hello World\");\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v01Xm-HcP08J",
        "outputId": "bc370782-fc1b-42ad-d148-d7519538e1c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helloWorld.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para compilarmos um código em c/C++ CUDA usaremos o compilador **nvcc**"
      ],
      "metadata": {
        "id": "vOM_0N9oPmWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO9yhW0-OWDs",
        "outputId": "eb639049-11b4-435d-da75-05fb83ffa6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jul 10 20:27:42 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc helloWorld.cu -o helloWorld"
      ],
      "metadata": {
        "id": "L84GzOARQKvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./helloWorld"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9HUYKrJQPK0",
        "outputId": "9ae2dec3-7581-4985-cb1e-a5fce077bef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello World"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dois novos elementos sintáticos são necessários para adicionarmos uma função a ser usada na placa gráfica:\n",
        "\n",
        "## \\_\\_global\\_\\_\n",
        "\n",
        "Indica que a função irá rodar na placa gráfica (*Device*)\n",
        "\n",
        "## mykernel<<<1,1>>>\n",
        "\n",
        "indica que a função *mykernel* irá ser executada no *device*\n",
        "\n",
        "Por enquanto iremos\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2xFO2_aI4ZDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helloDeviceOnly.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void mykernel(void) {\n",
        "}\n",
        "\n",
        "\n",
        "int main(void) {\n",
        "\n",
        "mykernel<<<1,1>>>();\n",
        "printf(\"Hello World!\\n\");\n",
        "return 0;\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iObs6E_QlRg",
        "outputId": "2bc44ccd-bdb6-42a9-b1a3-e2d504fcc476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing helloDeviceOnly.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc helloDeviceOnly.cu -o helloDeviceOnly\n",
        "!./helloDeviceOnly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cn7E9t3rdHKE",
        "outputId": "c6f93dad-69e4-4e7c-b44e-4bc961afc40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile soma.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "    *c = *a + *b;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main(void) {\n",
        "  int a, b, c;              // host copies of a, b, c\n",
        "  int *d_a, *d_b, *d_c;     // device copies of a, b, c\n",
        "  int size = sizeof(int);\n",
        "\n",
        "\n",
        "  // Allocate space for device copies of a, b, c\n",
        "  cudaMalloc((void **)&d_a, size);\n",
        "  cudaMalloc((void **)&d_b, size);\n",
        "  cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "  a = 2;\n",
        "  b = 7;\n",
        "\n",
        "  // Copy inputs to device\n",
        "  cudaMemcpy(d_a, &a, size, cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, &b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "  // Launch add() kernel on GPU\n",
        "  add<<<1,1>>>(d_a, d_b, d_c);\n",
        "\n",
        "  // Copy result back to host\n",
        "  cudaMemcpy(&c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "  printf(\"%d\\n\",c);\n",
        "\n",
        "  // Cleanup\n",
        "  cudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "return 0;\n",
        "\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kc95J6_2dOA0",
        "outputId": "495ee56c-71a8-4efa-f3a9-13684a4f2653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing soma.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc soma.cu -o soma\n",
        "!./soma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP-4N9g8eiq6",
        "outputId": "e8a4b81d-1cc4-4c1d-e2cb-0ccd98cd5a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A grande vantagem da execução de programas na GPU é sua alta capacidade de paralelismo. No exemplo a seguir iremos rodar a função add **N** vezes.\n",
        "\n",
        "Para isso iremos alterar a chamada da função add de:\n",
        "\n",
        "\n",
        "## add <<< 1, 1 >>> (  );\n",
        "\n",
        "para\n",
        "\n",
        "## add <<< ***N***, 1 >>> (   );\n",
        "\n",
        "Com isso agora podemos realizar uma função de soma em todos os elementos de um vetor.\n",
        "\n",
        "Já no corpo da função, iremos alterar a soma para a seguinte instrução:\n",
        "\n",
        "\n",
        "## c[blockIdx.x] = a[blockIdx.x] + b[blockIdx.x];\n",
        "\n",
        "Cada invocação de add se refere a um **Bloco** referenciado por seu índice de bloco chamado **blockIdx.x**.\n",
        "\n",
        "Um conjunto de blocos é chamado de **grid**.\n"
      ],
      "metadata": {
        "id": "1cF-XAZO1A1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile somaVetorial.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<time.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "\tc[blockIdx.x] = a[blockIdx.x] + b[blockIdx.x];\n",
        "}\n",
        "\n",
        "\n",
        "void random_ints(int *a, int N){\n",
        "\tint i;\n",
        "\n",
        "\tfor (i=0;i < N; i++){\n",
        "\t\ta[i] = rand() % 100;\n",
        "    printf(\"%3d \",a[i]);\n",
        "\t}\n",
        "  puts(\"\");\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "#define N 10\n",
        "\n",
        "int main(void) {\n",
        "\tint *a, *b, *c; // host copies of a, b, c\n",
        "\tint *d_a, *d_b, *d_c; // device copies of a, b, c\n",
        "\tint size = N * sizeof(int);\n",
        "\tint i;\n",
        "\n",
        "\n",
        "\t// Alloc space for device copies of a, b, c\n",
        "\tcudaMalloc((void **)&d_a, size);\n",
        "\tcudaMalloc((void **)&d_b, size);\n",
        "\tcudaMalloc((void **)&d_c, size);\n",
        "\n",
        "\tsrand(time(NULL));\n",
        "\n",
        "\t// Alloc space for host copies of a, b, c and setup input values\n",
        "\ta = (int *)malloc(size); random_ints(a, N);\n",
        "\tb = (int *)malloc(size); random_ints(b, N);\n",
        "\tc = (int *)malloc(size);\n",
        "\n",
        "\n",
        "\n",
        "\t// Copy inputs to device\n",
        "\tcudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\t// Launch add() kernel on GPU with N blocks\n",
        "\tadd<<<N,1>>>(d_a, d_b, d_c);\n",
        "\n",
        "\t// Copy result back to host\n",
        "\tcudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "\tfor (i = 0; i< N-1; i++){\n",
        "\t\tprintf(\"%d,\",c[i]);\n",
        "\t}\n",
        "\tprintf(\"%d\\n\",c[i]);\n",
        "\n",
        "\n",
        "\t// Cleanup\n",
        "\tfree(a); free(b); free(c);\n",
        "\tcudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\n",
        "\n",
        "\treturn 0;\n",
        "\t}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sm8lyp4TeqL-",
        "outputId": "e85906d3-311f-46d4-ebae-da2ff1b92cdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting somaVetorial.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc somaVetorial.cu -o somaVetorial\n",
        "!./somaVetorial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDxhc7nTkxGX",
        "outputId": "6f4cbfc9-2acf-485a-e2c4-aa3fd132e2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 41  39  85  74  96  57   4  66  81  23 \n",
            " 30  34  59  74   6  49  69  94   8  38 \n",
            "71,73,144,148,102,106,73,160,89,61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile somaVetorial_threads.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<time.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "\tc[threadIdx.x] = a[threadIdx.x] + b[threadIdx.x];\n",
        "}\n",
        "\n",
        "\n",
        "void random_ints(int *a, int N){\n",
        "\tint i;\n",
        "\n",
        "\tfor (i=0;i < N; i++){\n",
        "\t\ta[i] = rand() % 10;\n",
        "    printf(\"%3d \",a[i]);\n",
        "\t}\n",
        "  puts(\"\");\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "#define N 10\n",
        "\n",
        "int main(void) {\n",
        "\tint *a, *b, *c; // host copies of a, b, c\n",
        "\tint *d_a, *d_b, *d_c; // device copies of a, b, c\n",
        "\tint size = N * sizeof(int);\n",
        "\tint i;\n",
        "\n",
        "\n",
        "\t// Alloc space for device copies of a, b, c\n",
        "\tcudaMalloc((void **)&d_a, size);\n",
        "\tcudaMalloc((void **)&d_b, size);\n",
        "\tcudaMalloc((void **)&d_c, size);\n",
        "\n",
        "\tsrand(time(NULL));\n",
        "\n",
        "\t// Alloc space for host copies of a, b, c and setup input values\n",
        "\ta = (int *)malloc(size); random_ints(a, N);\n",
        "\tb = (int *)malloc(size); random_ints(b, N);\n",
        "\tc = (int *)malloc(size);\n",
        "\n",
        "\n",
        "\n",
        "\t// Copy inputs to device\n",
        "\tcudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\t// Launch add() kernel on GPU with N blocks\n",
        "\tadd<<<1,N>>>(d_a, d_b, d_c);\n",
        "\n",
        "\t// Copy result back to host\n",
        "\tcudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "\tfor (i = 0; i< N-1; i++){\n",
        "\t\tprintf(\"%d,\",c[i]);\n",
        "\t}\n",
        "\tprintf(\"%d\\n\",c[i]);\n",
        "\n",
        "\n",
        "\t// Cleanup\n",
        "\tfree(a); free(b); free(c);\n",
        "\tcudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\n",
        "\n",
        "\treturn 0;\n",
        "\t}"
      ],
      "metadata": {
        "id": "Cq3A2bkfk6ch",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf909fe1-40d5-4eb2-fdb0-babdf82fa01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting somaVetorial_threads.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc somaVetorial_threads.cu -o somaVetorial_threads\n",
        "!./somaVetorial_threads"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fdWP8QLVtAv",
        "outputId": "a9703576-d26e-4d8a-a394-221f96c1d549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  3   5   3   9   7   4   7   6   7   5 \n",
            "  0   0   3   9   1   9   9   9   2   5 \n",
            "3,5,6,18,8,13,16,15,9,10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos combinar o threads e blocos.\n",
        "\n",
        "Para cada bloco teremos uma quantidade de threads. Para acessarmos cada elemento podemos calcular um índice que leva em consideração a quantidade de **M** threads por bloco.\n",
        "\n",
        "int index =  threadIdx.x + blockIdx.x * M\n",
        "\n",
        "Identificaremos a quantidade de threads por bloco usando a variável **blockDim.x**\n",
        "\n",
        "int index =  threadIdx.x + blockIdx.x * blockDim.x\n",
        "\n"
      ],
      "metadata": {
        "id": "7BJyBEtN9Vik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile SomaVetorial_blocks_threads.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<time.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c) {\n",
        "\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\tc[index] = a[index] + b[index];\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "void random_ints(int *a, int N){\n",
        "\tint i;\n",
        "\n",
        "\tfor (i=0;i < N; i++){\n",
        "\t\ta[i] = rand() % 10;\n",
        "    printf(\"%-3d \",a[i]);\n",
        "\t}\n",
        "  puts(\"\");\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "#define N (128)\n",
        "#define THREADS_PER_BLOCK 8\n",
        "\n",
        "int main(void) {\n",
        "\tint *a, *b, *c; // host copies of a, b, c\n",
        "\tint *d_a, *d_b, *d_c; // device copies of a, b, c\n",
        "\tint size = N * sizeof(int);\n",
        "\tint i;\n",
        "\n",
        "\n",
        "\t// Alloc space for device copies of a, b, c\n",
        "\tcudaMalloc((void **)&d_a, size);\n",
        "\tcudaMalloc((void **)&d_b, size);\n",
        "\tcudaMalloc((void **)&d_c, size);\n",
        "\n",
        "\tsrand(time(NULL));\n",
        "\n",
        "\t// Alloc space for host copies of a, b, c and setup input values\n",
        "\ta = (int *)malloc(size); random_ints(a, N);\n",
        "\tb = (int *)malloc(size); random_ints(b, N);\n",
        "\tc = (int *)malloc(size);\n",
        "\n",
        "\n",
        "\n",
        "\t// Copy inputs to device\n",
        "\tcudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\t// Launch add() kernel on GPU with N blocks\n",
        "\tadd<<<N/THREADS_PER_BLOCK, THREADS_PER_BLOCK>>>(d_a, d_b, d_c);\n",
        "\n",
        "\t// Copy result back to host\n",
        "\tcudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "\tfor (i = 0; i< N-1; i++){\n",
        "\t\tprintf(\"%-3d,\",c[i]);\n",
        "\t}\n",
        "\tprintf(\"%-3d\\n\",c[i]);\n",
        "\n",
        "\n",
        "\t// Cleanup\n",
        "\tfree(a); free(b); free(c);\n",
        "\tcudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\n",
        "\n",
        "\treturn 0;\n",
        "\t}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-q1vKSb9Zjh",
        "outputId": "cba8d118-b832-47f7-f131-97eaf2d8c447"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting SomaVetorial_blocks_threads.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc SomaVetorial_blocks_threads.cu -o SomaVetorial_blocks_threads\n",
        "!./SomaVetorial_blocks_threads"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cphT2hNoCeZh",
        "outputId": "43767f91-3cfc-489f-a7e0-4303bc8edfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4   1   5   1   0   9   1   2   3   4   8   9   2   2   4   6   5   5   3   2   7   1   3   2   8   5   7   0   1   6   1   7   9   6   8   9   7   9   3   1   5   1   2   7   5   8   3   0   3   6   5   3   7   8   7   8   6   5   0   7   1   1   5   2   9   3   1   7   5   4   0   0   7   4   8   3   3   3   3   6   2   0   1   1   9   9   9   5   4   1   4   7   2   9   9   4   5   2   3   0   8   5   2   5   9   2   0   4   6   6   3   8   6   4   9   7   3   1   4   9   2   9   8   7   8   9   3   3   \n",
            "1   8   5   1   3   0   9   4   2   9   9   0   5   4   0   4   8   2   1   4   3   8   5   7   7   6   6   7   5   9   3   9   9   0   0   2   0   1   9   5   1   0   5   8   4   6   4   4   8   6   0   3   4   6   2   3   2   9   2   9   0   5   8   0   8   1   4   8   2   3   3   5   3   1   6   9   9   0   4   9   8   4   2   4   2   6   9   6   5   2   6   8   9   6   0   7   9   4   6   2   0   1   9   5   2   7   5   3   8   1   2   8   7   6   3   2   3   2   8   0   4   6   0   4   3   0   3   2   \n",
            "5  ,9  ,10 ,2  ,3  ,9  ,10 ,6  ,5  ,13 ,17 ,9  ,7  ,6  ,4  ,10 ,13 ,7  ,4  ,6  ,10 ,9  ,8  ,9  ,15 ,11 ,13 ,7  ,6  ,15 ,4  ,16 ,18 ,6  ,8  ,11 ,7  ,10 ,12 ,6  ,6  ,1  ,7  ,15 ,9  ,14 ,7  ,4  ,11 ,12 ,5  ,6  ,11 ,14 ,9  ,11 ,8  ,14 ,2  ,16 ,1  ,6  ,13 ,2  ,17 ,4  ,5  ,15 ,7  ,7  ,3  ,5  ,10 ,5  ,14 ,12 ,12 ,3  ,7  ,15 ,10 ,4  ,3  ,5  ,11 ,15 ,18 ,11 ,9  ,3  ,10 ,15 ,11 ,15 ,9  ,11 ,14 ,6  ,9  ,2  ,8  ,6  ,11 ,10 ,11 ,9  ,5  ,7  ,14 ,7  ,5  ,16 ,13 ,10 ,12 ,9  ,6  ,3  ,12 ,9  ,6  ,15 ,8  ,11 ,11 ,9  ,6  ,5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nem sempre **(na maioria das vezes)** não teremos N sendo um múltiplo de **blockDim.x**.\n",
        "\n",
        "Neste caso teremos que adaptar nosso código na chamada da função e dentro da função:"
      ],
      "metadata": {
        "id": "kNSr0wyLFBkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile SomaVetorial_blocks_threads_N_variavel.cu\n",
        "\n",
        "#include<stdio.h>\n",
        "#include<time.h>\n",
        "#include<stdlib.h>\n",
        "#include<cuda_runtime.h>\n",
        "\n",
        "\n",
        "\n",
        "__global__ void add(int *a, int *b, int *c, int n) {\n",
        "\n",
        "  int index = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\tif (index < n){\n",
        "    c[index] = a[index] + b[index];\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "void random_ints(int *a, int N){\n",
        "\tint i;\n",
        "\n",
        "\tfor (i=0;i < N; i++){\n",
        "\t\ta[i] = rand() % 10;\n",
        "    printf(\"%-3d \",a[i]);\n",
        "\t}\n",
        "  puts(\"\");\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "#define N (130)\n",
        "#define THREADS_PER_BLOCK 8\n",
        "\n",
        "int main(void) {\n",
        "\tint *a, *b, *c; // host copies of a, b, c\n",
        "\tint *d_a, *d_b, *d_c; // device copies of a, b, c\n",
        "\tint size = N * sizeof(int);\n",
        "\tint i;\n",
        "\n",
        "\n",
        "\t// Alloc space for device copies of a, b, c\n",
        "\tcudaMalloc((void **)&d_a, size);\n",
        "\tcudaMalloc((void **)&d_b, size);\n",
        "\tcudaMalloc((void **)&d_c, size);\n",
        "\n",
        "\tsrand(time(NULL));\n",
        "\n",
        "\t// Alloc space for host copies of a, b, c and setup input values\n",
        "\ta = (int *)malloc(size); random_ints(a, N);\n",
        "\tb = (int *)malloc(size); random_ints(b, N);\n",
        "\tc = (int *)malloc(size);\n",
        "\n",
        "\n",
        "\n",
        "\t// Copy inputs to device\n",
        "\tcudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\t// Launch add() kernel on GPU with N blocks\n",
        "\tadd<<< ((N + THREADS_PER_BLOCK-1) / THREADS_PER_BLOCK), THREADS_PER_BLOCK>>>(d_a, d_b, d_c,N);\n",
        "\n",
        "  // Sincronização do dispositivo\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "\t// Copy result back to host\n",
        "\tcudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\n",
        "\n",
        "\tfor (i = 0; i < N-1; i++){\n",
        "\t\tprintf(\"%-3d,\",c[i]);\n",
        "\t}\n",
        "\tprintf(\"%-3d\\n\",c[i]);\n",
        "\n",
        "\t// Cleanup\n",
        "\tfree(a); free(b); free(c);\n",
        "\tcudaFree(d_a); cudaFree(d_b); cudaFree(d_c);\n",
        "\n",
        "\n",
        "\treturn 0;\n",
        "\t}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh52i2mxFT-z",
        "outputId": "5df717bc-c24b-4a2f-9f15-9198524a225e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing SomaVetorial_blocks_threads_N_variavel.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc SomaVetorial_blocks_threads_N_variavel.cu -o SomaVetorial_blocks_threads_N_variavel\n",
        "!./SomaVetorial_blocks_threads_N_variavel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDvaN4csF-hp",
        "outputId": "a32a06a1-1026-4f69-d4d9-dbdaa56fe2a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4   7   9   6   4   6   8   7   4   4   9   6   6   2   3   6   5   3   8   4   2   2   6   0   8   0   3   7   6   6   0   2   3   1   1   9   0   9   9   4   5   8   0   1   0   5   7   7   8   7   4   2   0   2   3   0   2   8   7   0   4   9   3   0   0   6   9   0   5   8   6   2   8   8   3   1   3   2   0   4   1   4   6   3   6   1   3   8   1   0   1   8   9   4   8   2   0   9   4   7   0   1   9   8   9   4   9   5   6   0   9   7   6   7   3   3   1   6   3   2   9   4   0   0   0   0   2   0   0   9   \n",
            "9   2   0   0   0   1   4   2   6   2   4   7   2   0   5   5   3   6   1   9   0   0   3   3   1   6   3   5   8   5   4   8   9   6   0   0   8   5   4   6   7   8   4   9   8   1   4   2   9   8   3   1   8   6   4   1   4   0   7   3   7   1   1   7   8   1   9   8   8   3   6   8   1   2   9   9   5   6   3   4   4   6   6   2   5   2   4   9   2   3   2   0   4   5   9   4   9   8   4   7   1   3   5   4   5   7   5   1   3   1   7   7   9   3   1   4   6   7   6   0   0   0   2   5   8   1   1   7   9   6   \n",
            "13 ,9  ,9  ,6  ,4  ,7  ,12 ,9  ,10 ,6  ,13 ,13 ,8  ,2  ,8  ,11 ,8  ,9  ,9  ,13 ,2  ,2  ,9  ,3  ,9  ,6  ,6  ,12 ,14 ,11 ,4  ,10 ,12 ,7  ,1  ,9  ,8  ,14 ,13 ,10 ,12 ,16 ,4  ,10 ,8  ,6  ,11 ,9  ,17 ,15 ,7  ,3  ,8  ,8  ,7  ,1  ,6  ,8  ,14 ,3  ,11 ,10 ,4  ,7  ,8  ,7  ,18 ,8  ,13 ,11 ,12 ,10 ,9  ,10 ,12 ,10 ,8  ,8  ,3  ,8  ,5  ,10 ,12 ,5  ,11 ,3  ,7  ,17 ,3  ,3  ,3  ,8  ,13 ,9  ,17 ,6  ,9  ,17 ,8  ,14 ,1  ,4  ,14 ,12 ,14 ,11 ,14 ,6  ,9  ,1  ,16 ,14 ,15 ,10 ,4  ,7  ,7  ,13 ,9  ,2  ,9  ,4  ,2  ,5  ,8  ,1  ,3  ,7  ,9  ,15 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ta certo\n"
      ],
      "metadata": {
        "id": "HO67LpxY-Pmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile stencil1d.cu\n",
        "#include<stdio.h>\n",
        "#include<time.h>\n",
        "#include<stdlib.h>\n",
        "\n",
        "int const N =200;\n",
        "int const THREADS_PER_BLOCK =8;\n",
        "int const RADIUS =3;\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out){\n",
        "\n",
        "\t__shared__ int temp[N + 2 * RADIUS];\n",
        "\tint gindex = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\tint lindex = threadIdx.x + 3;\n",
        "\n",
        "\ttemp[lindex] = in[gindex];\n",
        "\tif (threadIdx.x < 3){\n",
        "\t\tif (gindex-RADIUS >= 0){\n",
        "\t\t\ttemp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "\t\t}\n",
        "\t\telse{\n",
        "\t\t\ttemp[lindex - RADIUS] = 0;\n",
        "\t\t}\n",
        "\t\tif (gindex + blockDim.x > N){\n",
        "\t\t\ttemp[lindex + RADIUS] = 0;\n",
        "\t\t}\n",
        "\t\telse{\n",
        "\t\t\ttemp[lindex + RADIUS] = in[gindex + blockDim.x];\n",
        "\t\t}\n",
        "\n",
        "\t}\n",
        "\n",
        "\t__syncthreads();\n",
        "\n",
        "\n",
        "\t// if (threadIdx.x == 5){\n",
        "\t// \tprintf(\"%d\\n%d --\\n\",lindex, temp[lindex]);\n",
        "\t// \tfor (int i=0; i< 8+2*3; i++){\n",
        "\t// \t\tprintf(\"%-3d\",temp[i]);\n",
        "\t// \t}\n",
        "\t// \tprintf(\"\\n\\n\\n\");\n",
        "\t// }\n",
        "\n",
        "\n",
        "\tint result = 0;\n",
        "\tfor (int offset = -RADIUS; offset <= RADIUS; offset++){\n",
        "\t\tresult += temp[lindex + offset];\n",
        "\t}\n",
        "\n",
        "\tout[gindex] = result;\n",
        "\n",
        "}\n",
        "\n",
        "\n",
        "void random_ints(int *a, int N){\n",
        "\tint i;\n",
        "\n",
        "\tfor (i=0;i < N; i++){\n",
        "\t\ta[i] = rand() % 10;\n",
        "    printf(\"%-3d \",a[i]);\n",
        "\t}\n",
        "  puts(\"\");\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "int main(void) {\n",
        "\tint *in, *out;\n",
        "\tint *d_in, *d_out;\n",
        "\tint size = N * sizeof(int);\n",
        "\tint i;\n",
        "\n",
        "\n",
        "\tcudaMalloc((void **)&d_in, size);\n",
        "\tcudaMalloc((void **)&d_out, size);\n",
        "\n",
        "\tsrand(1);\n",
        "\n",
        "\n",
        "\tin = (int *)malloc(size); random_ints(in, N);\n",
        "\tout = (int *)malloc(size);\n",
        "\n",
        "\n",
        "\t// Copy inputs to device\n",
        "\tcudaMemcpy(d_in, in, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_out, out, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tstencil_1d<<<((N + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK), THREADS_PER_BLOCK>>>(d_in, d_out);\n",
        "\n",
        "\t// Copy result back to host\n",
        "\tcudaMemcpy(out, d_out, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\tcudaDeviceSynchronize();\n",
        "\n",
        "\n",
        "\tfor (i = 0; i< N-1; i++){\n",
        "\t\tprintf(\"%-3d,\",out[i]);\n",
        "\t}\n",
        "\tprintf(\"%-3d\\n\",out[i]);\n",
        "\n",
        "\n",
        "\t// Cleanup\n",
        "\tfree(in); free(out);\n",
        "\tcudaFree(d_in); cudaFree(d_out);\n",
        "\n",
        "\n",
        "\treturn 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHhRlTYKVzjI",
        "outputId": "03ff8cf3-fb86-4424-e3b5-d6616540c926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing stencil1d.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc stencil1d.cu -o stencil1d\n",
        "!./stencil1d"
      ],
      "metadata": {
        "id": "cv_GkmurvXj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a15bce99-d714-41ad-aae7-70f55cd9ae15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3   6   7   5   3   5   6   2   9   1   2   7   0   9   3   6   0   6   2   6   1   8   7   9   2   0   2   3   7   5   9   2   2   8   9   7   3   6   1   2   9   3   1   9   4   7   8   4   5   0   3   6   1   0   6   3   2   0   6   1   5   5   4   7   6   5   6   9   3   7   4   5   2   5   4   7   4   4   3   0   7   8   6   8   8   4   3   1   4   9   2   0   6   8   9   2   6   6   4   9   5   0   4   8   7   1   7   2   7   2   2   6   1   0   6   1   5   9   4   9   0   9   1   7   7   1   1   5   9   7   7   6   7   3   6   5   6   3   9   4   8   1   2   9   3   9   0   8   8   5   0   9   6   3   8   5   6   1   1   5   9   8   4   8   1   0   3   0   4   4   4   4   7   6   3   1   7   5   9   6   2   1   7   8   5   7   4   1   8   5   9   7   5   3   8   8   3   1   8   9   \n",
            "21 ,24 ,29 ,35 ,34 ,28 ,21 ,16 ,32 ,27 ,30 ,31 ,28 ,27 ,25 ,18 ,32 ,24 ,29 ,30 ,39 ,33 ,31 ,25 ,31 ,30 ,28 ,28 ,28 ,28 ,26 ,23 ,42 ,40 ,37 ,36 ,36 ,28 ,19 ,12 ,31 ,29 ,35 ,41 ,36 ,33 ,32 ,23 ,33 ,27 ,19 ,21 ,19 ,19 ,16 ,10 ,18 ,23 ,22 ,23 ,28 ,28 ,22 ,21 ,42 ,40 ,43 ,40 ,39 ,34 ,28 ,19 ,34 ,31 ,31 ,29 ,27 ,22 ,18 ,11 ,36 ,40 ,41 ,44 ,38 ,30 ,24 ,16 ,23 ,25 ,30 ,38 ,36 ,27 ,25 ,25 ,44 ,41 ,32 ,34 ,36 ,30 ,26 ,17 ,29 ,36 ,34 ,28 ,27 ,26 ,19 ,17 ,18 ,21 ,28 ,26 ,34 ,34 ,28 ,27 ,39 ,37 ,34 ,26 ,31 ,22 ,21 ,14 ,36 ,42 ,44 ,45 ,41 ,34 ,27 ,21 ,36 ,41 ,36 ,33 ,36 ,33 ,24 ,20 ,32 ,39 ,42 ,33 ,39 ,30 ,30 ,22 ,36 ,37 ,38 ,30 ,29 ,26 ,18 ,13 ,36 ,36 ,35 ,33 ,24 ,16 ,12 ,4  ,19 ,26 ,29 ,32 ,29 ,25 ,21 ,17 ,37 ,33 ,31 ,37 ,38 ,33 ,24 ,18 ,33 ,40 ,38 ,39 ,41 ,34 ,30 ,29 ,45 ,43 ,35 ,36 ,40 ,37 ,29 ,21 \n"
          ]
        }
      ]
    }
  ]
}